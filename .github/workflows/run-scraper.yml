name: Run Amazon INF Scraper

# ==============================================================================
# ─── TRIGGERS ─────────────────────────────────────────────────────────────────
# This section defines WHEN the scraper runs.
# ==============================================================================
on:
  # 1. MANUAL TRIGGER: Allows you to run the scraper anytime from the "Actions" tab in GitHub.
  workflow_dispatch:

  # 2. SCHEDULED RUNS:
  #    This workflow runs at the start of EVERY hour. A check job then determines
  #    if it's the correct UK local time to proceed with the main scrape.
  schedule:
    - cron: '0 * * * *'

# Abort an older run of the same branch if a new one starts
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHON_VERSION: '3.11'
  # --- DEFINE YOUR TARGET UK HOURS HERE (24-hour format, space-separated) ---
  # The main job will only run if the current UK hour is in this list.
  # Example: '08 12 16' for 8am, 12pm, and 4pm.
  UK_TARGET_HOURS: '10 14 19'

jobs:
  # ==============================================================================
  # JOB 1: CHECK TIME
  # This job runs every hour, checks the current time in London, and decides
  # whether the main 'scrape' job should run.
  # ==============================================================================
  check-time:
    runs-on: ubuntu-latest
    outputs:
      # This output will be 'true' if it's the right time, 'false' otherwise.
      run_job: ${{ steps.check_hour.outputs.run_job }}
    steps:
      - name: Check current UK hour against target hours
        id: check_hour
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "Manual trigger detected. The main job will run."
            echo "run_job=true" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Get the current hour in London timezone (e.g., "09", "10", "17")
          CURRENT_UK_HOUR=$(TZ="Europe/London" date +'%H')

          echo "Current UK hour is: ${CURRENT_UK_HOUR}"
          echo "Target hours are: ${{ env.UK_TARGET_HOURS }}"

          # Check if the current hour is in our list of target hours
          if [[ " ${{ env.UK_TARGET_HOURS }} " =~ " ${CURRENT_UK_HOUR} " ]]; then
            echo "It's a target time. The main job will run."
            echo "run_job=true" >> $GITHUB_OUTPUT
          else
            echo "Not a target time. The main job will be skipped."
            echo "run_job=false" >> $GITHUB_OUTPUT
          fi

  # ==============================================================================
  # JOB 2: SCRAPE AND SUBMIT
  # This is the main job. It will ONLY run if the 'check-time' job above
  # determined that it's the correct time.
  # ==============================================================================
  scrape:
    needs: check-time
    if: needs.check-time.outputs.run_job == 'true'

    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
    - name: 1. Check out repository
      uses: actions/checkout@v4

    - name: 2. Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'

    - name: 3. Install Python dependencies
      run: pip install -r requirements.txt

    - name: 4. Install Playwright browsers & dependencies
      run: python -m playwright install --with-deps chromium

    - name: 5. Build config.json from Secrets
      # This step is tailored for the secrets needed by inf.py
      run: |
        echo '{
          "debug": false,
          "login_url": "https://sellercentral.amazon.co.uk/",
          "login_email": "${{ secrets.LOGIN_EMAIL }}",
          "login_password": "${{ secrets.LOGIN_PASSWORD }}",
          "otp_secret_key": "${{ secrets.OTP_SECRET_KEY }}",
          "inf_webhook_url": "${{ secrets.INF_WEBHOOK_URL }}",
          "target_store": {
            "store_name": "${{ secrets.TARGET_STORE_NAME }}",
            "merchant_id": "${{ secrets.TARGET_MERCHANT_ID }}",
            "marketplace_id": "${{ secrets.TARGET_MARKETPLACE_ID }}"
          }
        }' > config.json

    - name: 6. Run the INF scraper
      # Changed to run inf.py
      run: python inf.py

    - name: 7. Upload artifacts on failure or success
      # This allows you to download logs/output for debugging
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: inf-scraper-output-${{ github.run_id }}
        path: |
          output/
          inf_app.log
          state.json
        retention-days: 7